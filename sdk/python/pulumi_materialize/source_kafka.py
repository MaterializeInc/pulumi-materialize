# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs
from ._inputs import *

__all__ = ['SourceKafkaArgs', 'SourceKafka']

@pulumi.input_type
class SourceKafkaArgs:
    def __init__(__self__, *,
                 kafka_connection: pulumi.Input['SourceKafkaKafkaConnectionArgs'],
                 topic: pulumi.Input[str],
                 cluster_name: Optional[pulumi.Input[str]] = None,
                 database_name: Optional[pulumi.Input[str]] = None,
                 envelope: Optional[pulumi.Input['SourceKafkaEnvelopeArgs']] = None,
                 format: Optional[pulumi.Input['SourceKafkaFormatArgs']] = None,
                 include_headers: Optional[pulumi.Input[bool]] = None,
                 include_key: Optional[pulumi.Input[bool]] = None,
                 include_offset: Optional[pulumi.Input[bool]] = None,
                 include_partition: Optional[pulumi.Input[bool]] = None,
                 include_timestamp: Optional[pulumi.Input[bool]] = None,
                 key_format: Optional[pulumi.Input['SourceKafkaKeyFormatArgs']] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 primary_keys: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 schema_name: Optional[pulumi.Input[str]] = None,
                 size: Optional[pulumi.Input[str]] = None,
                 start_offsets: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 start_timestamp: Optional[pulumi.Input[int]] = None,
                 value_format: Optional[pulumi.Input['SourceKafkaValueFormatArgs']] = None):
        """
        The set of arguments for constructing a SourceKafka resource.
        :param pulumi.Input['SourceKafkaKafkaConnectionArgs'] kafka_connection: The Kafka connection to use in the source.
        :param pulumi.Input[str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[str] cluster_name: The cluster to maintain this source. If not specified, the size option must be specified.
        :param pulumi.Input[str] database_name: The identifier for the source database.
        :param pulumi.Input['SourceKafkaEnvelopeArgs'] envelope: How Materialize should interpret records (e.g. append-only, upsert)..
        :param pulumi.Input['SourceKafkaFormatArgs'] format: How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        :param pulumi.Input[bool] include_headers: Include message headers.
        :param pulumi.Input[bool] include_key: Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        :param pulumi.Input[bool] include_offset: Include an offset column containing the Kafka message offset.
        :param pulumi.Input[bool] include_partition: Include a partition column containing the Kafka message partition
        :param pulumi.Input[bool] include_timestamp: Include a timestamp column containing the Kafka message timestamp.
        :param pulumi.Input['SourceKafkaKeyFormatArgs'] key_format: Set the key format explicitly.
        :param pulumi.Input[str] name: The identifier for the source.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] primary_keys: Declare a set of columns as a primary key.
        :param pulumi.Input[str] schema_name: The identifier for the source schema.
        :param pulumi.Input[str] size: The size of the source.
        :param pulumi.Input[Sequence[pulumi.Input[int]]] start_offsets: Read partitions from the specified offset.
        :param pulumi.Input[int] start_timestamp: Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        :param pulumi.Input['SourceKafkaValueFormatArgs'] value_format: Set the value format explicitly.
        """
        pulumi.set(__self__, "kafka_connection", kafka_connection)
        pulumi.set(__self__, "topic", topic)
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)
        if envelope is not None:
            pulumi.set(__self__, "envelope", envelope)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if include_headers is not None:
            pulumi.set(__self__, "include_headers", include_headers)
        if include_key is not None:
            pulumi.set(__self__, "include_key", include_key)
        if include_offset is not None:
            pulumi.set(__self__, "include_offset", include_offset)
        if include_partition is not None:
            pulumi.set(__self__, "include_partition", include_partition)
        if include_timestamp is not None:
            pulumi.set(__self__, "include_timestamp", include_timestamp)
        if key_format is not None:
            pulumi.set(__self__, "key_format", key_format)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if primary_keys is not None:
            pulumi.set(__self__, "primary_keys", primary_keys)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if size is not None:
            pulumi.set(__self__, "size", size)
        if start_offsets is not None:
            pulumi.set(__self__, "start_offsets", start_offsets)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)
        if value_format is not None:
            pulumi.set(__self__, "value_format", value_format)

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> pulumi.Input['SourceKafkaKafkaConnectionArgs']:
        """
        The Kafka connection to use in the source.
        """
        return pulumi.get(self, "kafka_connection")

    @kafka_connection.setter
    def kafka_connection(self, value: pulumi.Input['SourceKafkaKafkaConnectionArgs']):
        pulumi.set(self, "kafka_connection", value)

    @property
    @pulumi.getter
    def topic(self) -> pulumi.Input[str]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: pulumi.Input[str]):
        pulumi.set(self, "topic", value)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[pulumi.Input[str]]:
        """
        The cluster to maintain this source. If not specified, the size option must be specified.
        """
        return pulumi.get(self, "cluster_name")

    @cluster_name.setter
    def cluster_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_name", value)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source database.
        """
        return pulumi.get(self, "database_name")

    @database_name.setter
    def database_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "database_name", value)

    @property
    @pulumi.getter
    def envelope(self) -> Optional[pulumi.Input['SourceKafkaEnvelopeArgs']]:
        """
        How Materialize should interpret records (e.g. append-only, upsert)..
        """
        return pulumi.get(self, "envelope")

    @envelope.setter
    def envelope(self, value: Optional[pulumi.Input['SourceKafkaEnvelopeArgs']]):
        pulumi.set(self, "envelope", value)

    @property
    @pulumi.getter
    def format(self) -> Optional[pulumi.Input['SourceKafkaFormatArgs']]:
        """
        How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        """
        return pulumi.get(self, "format")

    @format.setter
    def format(self, value: Optional[pulumi.Input['SourceKafkaFormatArgs']]):
        pulumi.set(self, "format", value)

    @property
    @pulumi.getter(name="includeHeaders")
    def include_headers(self) -> Optional[pulumi.Input[bool]]:
        """
        Include message headers.
        """
        return pulumi.get(self, "include_headers")

    @include_headers.setter
    def include_headers(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_headers", value)

    @property
    @pulumi.getter(name="includeKey")
    def include_key(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        """
        return pulumi.get(self, "include_key")

    @include_key.setter
    def include_key(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_key", value)

    @property
    @pulumi.getter(name="includeOffset")
    def include_offset(self) -> Optional[pulumi.Input[bool]]:
        """
        Include an offset column containing the Kafka message offset.
        """
        return pulumi.get(self, "include_offset")

    @include_offset.setter
    def include_offset(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_offset", value)

    @property
    @pulumi.getter(name="includePartition")
    def include_partition(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a partition column containing the Kafka message partition
        """
        return pulumi.get(self, "include_partition")

    @include_partition.setter
    def include_partition(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_partition", value)

    @property
    @pulumi.getter(name="includeTimestamp")
    def include_timestamp(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a timestamp column containing the Kafka message timestamp.
        """
        return pulumi.get(self, "include_timestamp")

    @include_timestamp.setter
    def include_timestamp(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_timestamp", value)

    @property
    @pulumi.getter(name="keyFormat")
    def key_format(self) -> Optional[pulumi.Input['SourceKafkaKeyFormatArgs']]:
        """
        Set the key format explicitly.
        """
        return pulumi.get(self, "key_format")

    @key_format.setter
    def key_format(self, value: Optional[pulumi.Input['SourceKafkaKeyFormatArgs']]):
        pulumi.set(self, "key_format", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Declare a set of columns as a primary key.
        """
        return pulumi.get(self, "primary_keys")

    @primary_keys.setter
    def primary_keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "primary_keys", value)

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source schema.
        """
        return pulumi.get(self, "schema_name")

    @schema_name.setter
    def schema_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "schema_name", value)

    @property
    @pulumi.getter
    def size(self) -> Optional[pulumi.Input[str]]:
        """
        The size of the source.
        """
        return pulumi.get(self, "size")

    @size.setter
    def size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "size", value)

    @property
    @pulumi.getter(name="startOffsets")
    def start_offsets(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]:
        """
        Read partitions from the specified offset.
        """
        return pulumi.get(self, "start_offsets")

    @start_offsets.setter
    def start_offsets(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]):
        pulumi.set(self, "start_offsets", value)

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[pulumi.Input[int]]:
        """
        Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        """
        return pulumi.get(self, "start_timestamp")

    @start_timestamp.setter
    def start_timestamp(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "start_timestamp", value)

    @property
    @pulumi.getter(name="valueFormat")
    def value_format(self) -> Optional[pulumi.Input['SourceKafkaValueFormatArgs']]:
        """
        Set the value format explicitly.
        """
        return pulumi.get(self, "value_format")

    @value_format.setter
    def value_format(self, value: Optional[pulumi.Input['SourceKafkaValueFormatArgs']]):
        pulumi.set(self, "value_format", value)


@pulumi.input_type
class _SourceKafkaState:
    def __init__(__self__, *,
                 cluster_name: Optional[pulumi.Input[str]] = None,
                 database_name: Optional[pulumi.Input[str]] = None,
                 envelope: Optional[pulumi.Input['SourceKafkaEnvelopeArgs']] = None,
                 format: Optional[pulumi.Input['SourceKafkaFormatArgs']] = None,
                 include_headers: Optional[pulumi.Input[bool]] = None,
                 include_key: Optional[pulumi.Input[bool]] = None,
                 include_offset: Optional[pulumi.Input[bool]] = None,
                 include_partition: Optional[pulumi.Input[bool]] = None,
                 include_timestamp: Optional[pulumi.Input[bool]] = None,
                 kafka_connection: Optional[pulumi.Input['SourceKafkaKafkaConnectionArgs']] = None,
                 key_format: Optional[pulumi.Input['SourceKafkaKeyFormatArgs']] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 primary_keys: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 qualified_sql_name: Optional[pulumi.Input[str]] = None,
                 schema_name: Optional[pulumi.Input[str]] = None,
                 size: Optional[pulumi.Input[str]] = None,
                 source_type: Optional[pulumi.Input[str]] = None,
                 start_offsets: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 start_timestamp: Optional[pulumi.Input[int]] = None,
                 topic: Optional[pulumi.Input[str]] = None,
                 value_format: Optional[pulumi.Input['SourceKafkaValueFormatArgs']] = None):
        """
        Input properties used for looking up and filtering SourceKafka resources.
        :param pulumi.Input[str] cluster_name: The cluster to maintain this source. If not specified, the size option must be specified.
        :param pulumi.Input[str] database_name: The identifier for the source database.
        :param pulumi.Input['SourceKafkaEnvelopeArgs'] envelope: How Materialize should interpret records (e.g. append-only, upsert)..
        :param pulumi.Input['SourceKafkaFormatArgs'] format: How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        :param pulumi.Input[bool] include_headers: Include message headers.
        :param pulumi.Input[bool] include_key: Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        :param pulumi.Input[bool] include_offset: Include an offset column containing the Kafka message offset.
        :param pulumi.Input[bool] include_partition: Include a partition column containing the Kafka message partition
        :param pulumi.Input[bool] include_timestamp: Include a timestamp column containing the Kafka message timestamp.
        :param pulumi.Input['SourceKafkaKafkaConnectionArgs'] kafka_connection: The Kafka connection to use in the source.
        :param pulumi.Input['SourceKafkaKeyFormatArgs'] key_format: Set the key format explicitly.
        :param pulumi.Input[str] name: The identifier for the source.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] primary_keys: Declare a set of columns as a primary key.
        :param pulumi.Input[str] qualified_sql_name: The fully qualified name of the source.
        :param pulumi.Input[str] schema_name: The identifier for the source schema.
        :param pulumi.Input[str] size: The size of the source.
        :param pulumi.Input[str] source_type: The type of source.
        :param pulumi.Input[Sequence[pulumi.Input[int]]] start_offsets: Read partitions from the specified offset.
        :param pulumi.Input[int] start_timestamp: Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        :param pulumi.Input[str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input['SourceKafkaValueFormatArgs'] value_format: Set the value format explicitly.
        """
        if cluster_name is not None:
            pulumi.set(__self__, "cluster_name", cluster_name)
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)
        if envelope is not None:
            pulumi.set(__self__, "envelope", envelope)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if include_headers is not None:
            pulumi.set(__self__, "include_headers", include_headers)
        if include_key is not None:
            pulumi.set(__self__, "include_key", include_key)
        if include_offset is not None:
            pulumi.set(__self__, "include_offset", include_offset)
        if include_partition is not None:
            pulumi.set(__self__, "include_partition", include_partition)
        if include_timestamp is not None:
            pulumi.set(__self__, "include_timestamp", include_timestamp)
        if kafka_connection is not None:
            pulumi.set(__self__, "kafka_connection", kafka_connection)
        if key_format is not None:
            pulumi.set(__self__, "key_format", key_format)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if primary_keys is not None:
            pulumi.set(__self__, "primary_keys", primary_keys)
        if qualified_sql_name is not None:
            pulumi.set(__self__, "qualified_sql_name", qualified_sql_name)
        if schema_name is not None:
            pulumi.set(__self__, "schema_name", schema_name)
        if size is not None:
            pulumi.set(__self__, "size", size)
        if source_type is not None:
            pulumi.set(__self__, "source_type", source_type)
        if start_offsets is not None:
            pulumi.set(__self__, "start_offsets", start_offsets)
        if start_timestamp is not None:
            pulumi.set(__self__, "start_timestamp", start_timestamp)
        if topic is not None:
            pulumi.set(__self__, "topic", topic)
        if value_format is not None:
            pulumi.set(__self__, "value_format", value_format)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> Optional[pulumi.Input[str]]:
        """
        The cluster to maintain this source. If not specified, the size option must be specified.
        """
        return pulumi.get(self, "cluster_name")

    @cluster_name.setter
    def cluster_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "cluster_name", value)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source database.
        """
        return pulumi.get(self, "database_name")

    @database_name.setter
    def database_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "database_name", value)

    @property
    @pulumi.getter
    def envelope(self) -> Optional[pulumi.Input['SourceKafkaEnvelopeArgs']]:
        """
        How Materialize should interpret records (e.g. append-only, upsert)..
        """
        return pulumi.get(self, "envelope")

    @envelope.setter
    def envelope(self, value: Optional[pulumi.Input['SourceKafkaEnvelopeArgs']]):
        pulumi.set(self, "envelope", value)

    @property
    @pulumi.getter
    def format(self) -> Optional[pulumi.Input['SourceKafkaFormatArgs']]:
        """
        How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        """
        return pulumi.get(self, "format")

    @format.setter
    def format(self, value: Optional[pulumi.Input['SourceKafkaFormatArgs']]):
        pulumi.set(self, "format", value)

    @property
    @pulumi.getter(name="includeHeaders")
    def include_headers(self) -> Optional[pulumi.Input[bool]]:
        """
        Include message headers.
        """
        return pulumi.get(self, "include_headers")

    @include_headers.setter
    def include_headers(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_headers", value)

    @property
    @pulumi.getter(name="includeKey")
    def include_key(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        """
        return pulumi.get(self, "include_key")

    @include_key.setter
    def include_key(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_key", value)

    @property
    @pulumi.getter(name="includeOffset")
    def include_offset(self) -> Optional[pulumi.Input[bool]]:
        """
        Include an offset column containing the Kafka message offset.
        """
        return pulumi.get(self, "include_offset")

    @include_offset.setter
    def include_offset(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_offset", value)

    @property
    @pulumi.getter(name="includePartition")
    def include_partition(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a partition column containing the Kafka message partition
        """
        return pulumi.get(self, "include_partition")

    @include_partition.setter
    def include_partition(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_partition", value)

    @property
    @pulumi.getter(name="includeTimestamp")
    def include_timestamp(self) -> Optional[pulumi.Input[bool]]:
        """
        Include a timestamp column containing the Kafka message timestamp.
        """
        return pulumi.get(self, "include_timestamp")

    @include_timestamp.setter
    def include_timestamp(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "include_timestamp", value)

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> Optional[pulumi.Input['SourceKafkaKafkaConnectionArgs']]:
        """
        The Kafka connection to use in the source.
        """
        return pulumi.get(self, "kafka_connection")

    @kafka_connection.setter
    def kafka_connection(self, value: Optional[pulumi.Input['SourceKafkaKafkaConnectionArgs']]):
        pulumi.set(self, "kafka_connection", value)

    @property
    @pulumi.getter(name="keyFormat")
    def key_format(self) -> Optional[pulumi.Input['SourceKafkaKeyFormatArgs']]:
        """
        Set the key format explicitly.
        """
        return pulumi.get(self, "key_format")

    @key_format.setter
    def key_format(self, value: Optional[pulumi.Input['SourceKafkaKeyFormatArgs']]):
        pulumi.set(self, "key_format", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Declare a set of columns as a primary key.
        """
        return pulumi.get(self, "primary_keys")

    @primary_keys.setter
    def primary_keys(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "primary_keys", value)

    @property
    @pulumi.getter(name="qualifiedSqlName")
    def qualified_sql_name(self) -> Optional[pulumi.Input[str]]:
        """
        The fully qualified name of the source.
        """
        return pulumi.get(self, "qualified_sql_name")

    @qualified_sql_name.setter
    def qualified_sql_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "qualified_sql_name", value)

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> Optional[pulumi.Input[str]]:
        """
        The identifier for the source schema.
        """
        return pulumi.get(self, "schema_name")

    @schema_name.setter
    def schema_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "schema_name", value)

    @property
    @pulumi.getter
    def size(self) -> Optional[pulumi.Input[str]]:
        """
        The size of the source.
        """
        return pulumi.get(self, "size")

    @size.setter
    def size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "size", value)

    @property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> Optional[pulumi.Input[str]]:
        """
        The type of source.
        """
        return pulumi.get(self, "source_type")

    @source_type.setter
    def source_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "source_type", value)

    @property
    @pulumi.getter(name="startOffsets")
    def start_offsets(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]:
        """
        Read partitions from the specified offset.
        """
        return pulumi.get(self, "start_offsets")

    @start_offsets.setter
    def start_offsets(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]]):
        pulumi.set(self, "start_offsets", value)

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> Optional[pulumi.Input[int]]:
        """
        Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        """
        return pulumi.get(self, "start_timestamp")

    @start_timestamp.setter
    def start_timestamp(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "start_timestamp", value)

    @property
    @pulumi.getter
    def topic(self) -> Optional[pulumi.Input[str]]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @topic.setter
    def topic(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "topic", value)

    @property
    @pulumi.getter(name="valueFormat")
    def value_format(self) -> Optional[pulumi.Input['SourceKafkaValueFormatArgs']]:
        """
        Set the value format explicitly.
        """
        return pulumi.get(self, "value_format")

    @value_format.setter
    def value_format(self, value: Optional[pulumi.Input['SourceKafkaValueFormatArgs']]):
        pulumi.set(self, "value_format", value)


class SourceKafka(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 cluster_name: Optional[pulumi.Input[str]] = None,
                 database_name: Optional[pulumi.Input[str]] = None,
                 envelope: Optional[pulumi.Input[pulumi.InputType['SourceKafkaEnvelopeArgs']]] = None,
                 format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaFormatArgs']]] = None,
                 include_headers: Optional[pulumi.Input[bool]] = None,
                 include_key: Optional[pulumi.Input[bool]] = None,
                 include_offset: Optional[pulumi.Input[bool]] = None,
                 include_partition: Optional[pulumi.Input[bool]] = None,
                 include_timestamp: Optional[pulumi.Input[bool]] = None,
                 kafka_connection: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKafkaConnectionArgs']]] = None,
                 key_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKeyFormatArgs']]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 primary_keys: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 schema_name: Optional[pulumi.Input[str]] = None,
                 size: Optional[pulumi.Input[str]] = None,
                 start_offsets: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 start_timestamp: Optional[pulumi.Input[int]] = None,
                 topic: Optional[pulumi.Input[str]] = None,
                 value_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaValueFormatArgs']]] = None,
                 __props__=None):
        """
        A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.

        ## Example Usage

        ```python
        import pulumi
        import pulumi_materialize as materialize

        example_source_kafka = materialize.SourceKafka("exampleSourceKafka",
            envelope=materialize.SourceKafkaEnvelopeArgs(
                none=True,
            ),
            format=materialize.SourceKafkaFormatArgs(
                avro=materialize.SourceKafkaFormatAvroArgs(
                    schema_registry_connection=materialize.SourceKafkaFormatAvroSchemaRegistryConnectionArgs(
                        database_name="database",
                        name="csr_connection",
                        schema_name="schema",
                    ),
                ),
            ),
            kafka_connection=materialize.SourceKafkaKafkaConnectionArgs(
                database_name="database",
                name="kafka_connection",
                schema_name="schema",
            ),
            schema_name="schema",
            size="3xsmall")
        ```

        ## Import

        # Sources can be imported using the source id

        ```sh
         $ pulumi import materialize:index/sourceKafka:SourceKafka example_source_kafka <source_id>
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[str] cluster_name: The cluster to maintain this source. If not specified, the size option must be specified.
        :param pulumi.Input[str] database_name: The identifier for the source database.
        :param pulumi.Input[pulumi.InputType['SourceKafkaEnvelopeArgs']] envelope: How Materialize should interpret records (e.g. append-only, upsert)..
        :param pulumi.Input[pulumi.InputType['SourceKafkaFormatArgs']] format: How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        :param pulumi.Input[bool] include_headers: Include message headers.
        :param pulumi.Input[bool] include_key: Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        :param pulumi.Input[bool] include_offset: Include an offset column containing the Kafka message offset.
        :param pulumi.Input[bool] include_partition: Include a partition column containing the Kafka message partition
        :param pulumi.Input[bool] include_timestamp: Include a timestamp column containing the Kafka message timestamp.
        :param pulumi.Input[pulumi.InputType['SourceKafkaKafkaConnectionArgs']] kafka_connection: The Kafka connection to use in the source.
        :param pulumi.Input[pulumi.InputType['SourceKafkaKeyFormatArgs']] key_format: Set the key format explicitly.
        :param pulumi.Input[str] name: The identifier for the source.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] primary_keys: Declare a set of columns as a primary key.
        :param pulumi.Input[str] schema_name: The identifier for the source schema.
        :param pulumi.Input[str] size: The size of the source.
        :param pulumi.Input[Sequence[pulumi.Input[int]]] start_offsets: Read partitions from the specified offset.
        :param pulumi.Input[int] start_timestamp: Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        :param pulumi.Input[str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[pulumi.InputType['SourceKafkaValueFormatArgs']] value_format: Set the value format explicitly.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: SourceKafkaArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.

        ## Example Usage

        ```python
        import pulumi
        import pulumi_materialize as materialize

        example_source_kafka = materialize.SourceKafka("exampleSourceKafka",
            envelope=materialize.SourceKafkaEnvelopeArgs(
                none=True,
            ),
            format=materialize.SourceKafkaFormatArgs(
                avro=materialize.SourceKafkaFormatAvroArgs(
                    schema_registry_connection=materialize.SourceKafkaFormatAvroSchemaRegistryConnectionArgs(
                        database_name="database",
                        name="csr_connection",
                        schema_name="schema",
                    ),
                ),
            ),
            kafka_connection=materialize.SourceKafkaKafkaConnectionArgs(
                database_name="database",
                name="kafka_connection",
                schema_name="schema",
            ),
            schema_name="schema",
            size="3xsmall")
        ```

        ## Import

        # Sources can be imported using the source id

        ```sh
         $ pulumi import materialize:index/sourceKafka:SourceKafka example_source_kafka <source_id>
        ```

        :param str resource_name: The name of the resource.
        :param SourceKafkaArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(SourceKafkaArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 cluster_name: Optional[pulumi.Input[str]] = None,
                 database_name: Optional[pulumi.Input[str]] = None,
                 envelope: Optional[pulumi.Input[pulumi.InputType['SourceKafkaEnvelopeArgs']]] = None,
                 format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaFormatArgs']]] = None,
                 include_headers: Optional[pulumi.Input[bool]] = None,
                 include_key: Optional[pulumi.Input[bool]] = None,
                 include_offset: Optional[pulumi.Input[bool]] = None,
                 include_partition: Optional[pulumi.Input[bool]] = None,
                 include_timestamp: Optional[pulumi.Input[bool]] = None,
                 kafka_connection: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKafkaConnectionArgs']]] = None,
                 key_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKeyFormatArgs']]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 primary_keys: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 schema_name: Optional[pulumi.Input[str]] = None,
                 size: Optional[pulumi.Input[str]] = None,
                 start_offsets: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
                 start_timestamp: Optional[pulumi.Input[int]] = None,
                 topic: Optional[pulumi.Input[str]] = None,
                 value_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaValueFormatArgs']]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = SourceKafkaArgs.__new__(SourceKafkaArgs)

            __props__.__dict__["cluster_name"] = cluster_name
            __props__.__dict__["database_name"] = database_name
            __props__.__dict__["envelope"] = envelope
            __props__.__dict__["format"] = format
            __props__.__dict__["include_headers"] = include_headers
            __props__.__dict__["include_key"] = include_key
            __props__.__dict__["include_offset"] = include_offset
            __props__.__dict__["include_partition"] = include_partition
            __props__.__dict__["include_timestamp"] = include_timestamp
            if kafka_connection is None and not opts.urn:
                raise TypeError("Missing required property 'kafka_connection'")
            __props__.__dict__["kafka_connection"] = kafka_connection
            __props__.__dict__["key_format"] = key_format
            __props__.__dict__["name"] = name
            __props__.__dict__["primary_keys"] = primary_keys
            __props__.__dict__["schema_name"] = schema_name
            __props__.__dict__["size"] = size
            __props__.__dict__["start_offsets"] = start_offsets
            __props__.__dict__["start_timestamp"] = start_timestamp
            if topic is None and not opts.urn:
                raise TypeError("Missing required property 'topic'")
            __props__.__dict__["topic"] = topic
            __props__.__dict__["value_format"] = value_format
            __props__.__dict__["qualified_sql_name"] = None
            __props__.__dict__["source_type"] = None
        super(SourceKafka, __self__).__init__(
            'materialize:index/sourceKafka:SourceKafka',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None,
            cluster_name: Optional[pulumi.Input[str]] = None,
            database_name: Optional[pulumi.Input[str]] = None,
            envelope: Optional[pulumi.Input[pulumi.InputType['SourceKafkaEnvelopeArgs']]] = None,
            format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaFormatArgs']]] = None,
            include_headers: Optional[pulumi.Input[bool]] = None,
            include_key: Optional[pulumi.Input[bool]] = None,
            include_offset: Optional[pulumi.Input[bool]] = None,
            include_partition: Optional[pulumi.Input[bool]] = None,
            include_timestamp: Optional[pulumi.Input[bool]] = None,
            kafka_connection: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKafkaConnectionArgs']]] = None,
            key_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaKeyFormatArgs']]] = None,
            name: Optional[pulumi.Input[str]] = None,
            primary_keys: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
            qualified_sql_name: Optional[pulumi.Input[str]] = None,
            schema_name: Optional[pulumi.Input[str]] = None,
            size: Optional[pulumi.Input[str]] = None,
            source_type: Optional[pulumi.Input[str]] = None,
            start_offsets: Optional[pulumi.Input[Sequence[pulumi.Input[int]]]] = None,
            start_timestamp: Optional[pulumi.Input[int]] = None,
            topic: Optional[pulumi.Input[str]] = None,
            value_format: Optional[pulumi.Input[pulumi.InputType['SourceKafkaValueFormatArgs']]] = None) -> 'SourceKafka':
        """
        Get an existing SourceKafka resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[str] cluster_name: The cluster to maintain this source. If not specified, the size option must be specified.
        :param pulumi.Input[str] database_name: The identifier for the source database.
        :param pulumi.Input[pulumi.InputType['SourceKafkaEnvelopeArgs']] envelope: How Materialize should interpret records (e.g. append-only, upsert)..
        :param pulumi.Input[pulumi.InputType['SourceKafkaFormatArgs']] format: How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        :param pulumi.Input[bool] include_headers: Include message headers.
        :param pulumi.Input[bool] include_key: Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        :param pulumi.Input[bool] include_offset: Include an offset column containing the Kafka message offset.
        :param pulumi.Input[bool] include_partition: Include a partition column containing the Kafka message partition
        :param pulumi.Input[bool] include_timestamp: Include a timestamp column containing the Kafka message timestamp.
        :param pulumi.Input[pulumi.InputType['SourceKafkaKafkaConnectionArgs']] kafka_connection: The Kafka connection to use in the source.
        :param pulumi.Input[pulumi.InputType['SourceKafkaKeyFormatArgs']] key_format: Set the key format explicitly.
        :param pulumi.Input[str] name: The identifier for the source.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] primary_keys: Declare a set of columns as a primary key.
        :param pulumi.Input[str] qualified_sql_name: The fully qualified name of the source.
        :param pulumi.Input[str] schema_name: The identifier for the source schema.
        :param pulumi.Input[str] size: The size of the source.
        :param pulumi.Input[str] source_type: The type of source.
        :param pulumi.Input[Sequence[pulumi.Input[int]]] start_offsets: Read partitions from the specified offset.
        :param pulumi.Input[int] start_timestamp: Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        :param pulumi.Input[str] topic: The Kafka topic you want to subscribe to.
        :param pulumi.Input[pulumi.InputType['SourceKafkaValueFormatArgs']] value_format: Set the value format explicitly.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = _SourceKafkaState.__new__(_SourceKafkaState)

        __props__.__dict__["cluster_name"] = cluster_name
        __props__.__dict__["database_name"] = database_name
        __props__.__dict__["envelope"] = envelope
        __props__.__dict__["format"] = format
        __props__.__dict__["include_headers"] = include_headers
        __props__.__dict__["include_key"] = include_key
        __props__.__dict__["include_offset"] = include_offset
        __props__.__dict__["include_partition"] = include_partition
        __props__.__dict__["include_timestamp"] = include_timestamp
        __props__.__dict__["kafka_connection"] = kafka_connection
        __props__.__dict__["key_format"] = key_format
        __props__.__dict__["name"] = name
        __props__.__dict__["primary_keys"] = primary_keys
        __props__.__dict__["qualified_sql_name"] = qualified_sql_name
        __props__.__dict__["schema_name"] = schema_name
        __props__.__dict__["size"] = size
        __props__.__dict__["source_type"] = source_type
        __props__.__dict__["start_offsets"] = start_offsets
        __props__.__dict__["start_timestamp"] = start_timestamp
        __props__.__dict__["topic"] = topic
        __props__.__dict__["value_format"] = value_format
        return SourceKafka(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter(name="clusterName")
    def cluster_name(self) -> pulumi.Output[str]:
        """
        The cluster to maintain this source. If not specified, the size option must be specified.
        """
        return pulumi.get(self, "cluster_name")

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> pulumi.Output[Optional[str]]:
        """
        The identifier for the source database.
        """
        return pulumi.get(self, "database_name")

    @property
    @pulumi.getter
    def envelope(self) -> pulumi.Output[Optional['outputs.SourceKafkaEnvelope']]:
        """
        How Materialize should interpret records (e.g. append-only, upsert)..
        """
        return pulumi.get(self, "envelope")

    @property
    @pulumi.getter
    def format(self) -> pulumi.Output[Optional['outputs.SourceKafkaFormat']]:
        """
        How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
        """
        return pulumi.get(self, "format")

    @property
    @pulumi.getter(name="includeHeaders")
    def include_headers(self) -> pulumi.Output[Optional[bool]]:
        """
        Include message headers.
        """
        return pulumi.get(self, "include_headers")

    @property
    @pulumi.getter(name="includeKey")
    def include_key(self) -> pulumi.Output[Optional[bool]]:
        """
        Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
        """
        return pulumi.get(self, "include_key")

    @property
    @pulumi.getter(name="includeOffset")
    def include_offset(self) -> pulumi.Output[Optional[bool]]:
        """
        Include an offset column containing the Kafka message offset.
        """
        return pulumi.get(self, "include_offset")

    @property
    @pulumi.getter(name="includePartition")
    def include_partition(self) -> pulumi.Output[Optional[bool]]:
        """
        Include a partition column containing the Kafka message partition
        """
        return pulumi.get(self, "include_partition")

    @property
    @pulumi.getter(name="includeTimestamp")
    def include_timestamp(self) -> pulumi.Output[Optional[bool]]:
        """
        Include a timestamp column containing the Kafka message timestamp.
        """
        return pulumi.get(self, "include_timestamp")

    @property
    @pulumi.getter(name="kafkaConnection")
    def kafka_connection(self) -> pulumi.Output['outputs.SourceKafkaKafkaConnection']:
        """
        The Kafka connection to use in the source.
        """
        return pulumi.get(self, "kafka_connection")

    @property
    @pulumi.getter(name="keyFormat")
    def key_format(self) -> pulumi.Output[Optional['outputs.SourceKafkaKeyFormat']]:
        """
        Set the key format explicitly.
        """
        return pulumi.get(self, "key_format")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[str]:
        """
        The identifier for the source.
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter(name="primaryKeys")
    def primary_keys(self) -> pulumi.Output[Optional[Sequence[str]]]:
        """
        Declare a set of columns as a primary key.
        """
        return pulumi.get(self, "primary_keys")

    @property
    @pulumi.getter(name="qualifiedSqlName")
    def qualified_sql_name(self) -> pulumi.Output[str]:
        """
        The fully qualified name of the source.
        """
        return pulumi.get(self, "qualified_sql_name")

    @property
    @pulumi.getter(name="schemaName")
    def schema_name(self) -> pulumi.Output[Optional[str]]:
        """
        The identifier for the source schema.
        """
        return pulumi.get(self, "schema_name")

    @property
    @pulumi.getter
    def size(self) -> pulumi.Output[str]:
        """
        The size of the source.
        """
        return pulumi.get(self, "size")

    @property
    @pulumi.getter(name="sourceType")
    def source_type(self) -> pulumi.Output[str]:
        """
        The type of source.
        """
        return pulumi.get(self, "source_type")

    @property
    @pulumi.getter(name="startOffsets")
    def start_offsets(self) -> pulumi.Output[Optional[Sequence[int]]]:
        """
        Read partitions from the specified offset.
        """
        return pulumi.get(self, "start_offsets")

    @property
    @pulumi.getter(name="startTimestamp")
    def start_timestamp(self) -> pulumi.Output[Optional[int]]:
        """
        Use the specified value to set "START OFFSET" based on the Kafka timestamp.
        """
        return pulumi.get(self, "start_timestamp")

    @property
    @pulumi.getter
    def topic(self) -> pulumi.Output[str]:
        """
        The Kafka topic you want to subscribe to.
        """
        return pulumi.get(self, "topic")

    @property
    @pulumi.getter(name="valueFormat")
    def value_format(self) -> pulumi.Output[Optional['outputs.SourceKafkaValueFormat']]:
        """
        Set the value format explicitly.
        """
        return pulumi.get(self, "value_format")

