// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package materialize

import (
	"context"
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.
//
// ## Example Usage
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi-materialize/sdk/go/materialize"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := materialize.NewSourceKafka(ctx, "exampleSourceKafka", &materialize.SourceKafkaArgs{
//				Envelope: &SourceKafkaEnvelopeArgs{
//					None: pulumi.Bool(true),
//				},
//				Format: &SourceKafkaFormatArgs{
//					Avro: &SourceKafkaFormatAvroArgs{
//						SchemaRegistryConnection: &SourceKafkaFormatAvroSchemaRegistryConnectionArgs{
//							DatabaseName: pulumi.String("database"),
//							Name:         pulumi.String("csr_connection"),
//							SchemaName:   pulumi.String("schema"),
//						},
//					},
//				},
//				KafkaConnection: &SourceKafkaKafkaConnectionArgs{
//					DatabaseName: pulumi.String("database"),
//					Name:         pulumi.String("kafka_connection"),
//					SchemaName:   pulumi.String("schema"),
//				},
//				SchemaName: pulumi.String("schema"),
//				Size:       pulumi.String("3xsmall"),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// # Sources can be imported using the source id
//
// ```sh
//
//	$ pulumi import materialize:index/sourceKafka:SourceKafka example_source_kafka <source_id>
//
// ```
type SourceKafka struct {
	pulumi.CustomResourceState

	// The cluster to maintain this source. If not specified, the size option must be specified.
	ClusterName pulumi.StringOutput `pulumi:"clusterName"`
	// The identifier for the source database.
	DatabaseName pulumi.StringPtrOutput `pulumi:"databaseName"`
	// How Materialize should interpret records (e.g. append-only, upsert)..
	Envelope SourceKafkaEnvelopePtrOutput `pulumi:"envelope"`
	// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
	Format SourceKafkaFormatPtrOutput `pulumi:"format"`
	// Include message headers.
	IncludeHeaders pulumi.BoolPtrOutput `pulumi:"includeHeaders"`
	// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
	IncludeKey pulumi.BoolPtrOutput `pulumi:"includeKey"`
	// Include an offset column containing the Kafka message offset.
	IncludeOffset pulumi.BoolPtrOutput `pulumi:"includeOffset"`
	// Include a partition column containing the Kafka message partition
	IncludePartition pulumi.BoolPtrOutput `pulumi:"includePartition"`
	// Include a timestamp column containing the Kafka message timestamp.
	IncludeTimestamp pulumi.BoolPtrOutput `pulumi:"includeTimestamp"`
	// The Kafka connection to use in the source.
	KafkaConnection SourceKafkaKafkaConnectionOutput `pulumi:"kafkaConnection"`
	// Set the key format explicitly.
	KeyFormat SourceKafkaKeyFormatPtrOutput `pulumi:"keyFormat"`
	// The identifier for the source.
	Name pulumi.StringOutput `pulumi:"name"`
	// Declare a set of columns as a primary key.
	PrimaryKeys pulumi.StringArrayOutput `pulumi:"primaryKeys"`
	// The fully qualified name of the source.
	QualifiedSqlName pulumi.StringOutput `pulumi:"qualifiedSqlName"`
	// The identifier for the source schema.
	SchemaName pulumi.StringPtrOutput `pulumi:"schemaName"`
	// The size of the source.
	Size pulumi.StringOutput `pulumi:"size"`
	// The type of source.
	SourceType pulumi.StringOutput `pulumi:"sourceType"`
	// Read partitions from the specified offset.
	StartOffsets pulumi.IntArrayOutput `pulumi:"startOffsets"`
	// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
	StartTimestamp pulumi.IntPtrOutput `pulumi:"startTimestamp"`
	// The Kafka topic you want to subscribe to.
	Topic pulumi.StringOutput `pulumi:"topic"`
	// Set the value format explicitly.
	ValueFormat SourceKafkaValueFormatPtrOutput `pulumi:"valueFormat"`
}

// NewSourceKafka registers a new resource with the given unique name, arguments, and options.
func NewSourceKafka(ctx *pulumi.Context,
	name string, args *SourceKafkaArgs, opts ...pulumi.ResourceOption) (*SourceKafka, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.KafkaConnection == nil {
		return nil, errors.New("invalid value for required argument 'KafkaConnection'")
	}
	if args.Topic == nil {
		return nil, errors.New("invalid value for required argument 'Topic'")
	}
	opts = pkgResourceDefaultOpts(opts)
	var resource SourceKafka
	err := ctx.RegisterResource("materialize:index/sourceKafka:SourceKafka", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetSourceKafka gets an existing SourceKafka resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetSourceKafka(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *SourceKafkaState, opts ...pulumi.ResourceOption) (*SourceKafka, error) {
	var resource SourceKafka
	err := ctx.ReadResource("materialize:index/sourceKafka:SourceKafka", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering SourceKafka resources.
type sourceKafkaState struct {
	// The cluster to maintain this source. If not specified, the size option must be specified.
	ClusterName *string `pulumi:"clusterName"`
	// The identifier for the source database.
	DatabaseName *string `pulumi:"databaseName"`
	// How Materialize should interpret records (e.g. append-only, upsert)..
	Envelope *SourceKafkaEnvelope `pulumi:"envelope"`
	// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
	Format *SourceKafkaFormat `pulumi:"format"`
	// Include message headers.
	IncludeHeaders *bool `pulumi:"includeHeaders"`
	// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
	IncludeKey *bool `pulumi:"includeKey"`
	// Include an offset column containing the Kafka message offset.
	IncludeOffset *bool `pulumi:"includeOffset"`
	// Include a partition column containing the Kafka message partition
	IncludePartition *bool `pulumi:"includePartition"`
	// Include a timestamp column containing the Kafka message timestamp.
	IncludeTimestamp *bool `pulumi:"includeTimestamp"`
	// The Kafka connection to use in the source.
	KafkaConnection *SourceKafkaKafkaConnection `pulumi:"kafkaConnection"`
	// Set the key format explicitly.
	KeyFormat *SourceKafkaKeyFormat `pulumi:"keyFormat"`
	// The identifier for the source.
	Name *string `pulumi:"name"`
	// Declare a set of columns as a primary key.
	PrimaryKeys []string `pulumi:"primaryKeys"`
	// The fully qualified name of the source.
	QualifiedSqlName *string `pulumi:"qualifiedSqlName"`
	// The identifier for the source schema.
	SchemaName *string `pulumi:"schemaName"`
	// The size of the source.
	Size *string `pulumi:"size"`
	// The type of source.
	SourceType *string `pulumi:"sourceType"`
	// Read partitions from the specified offset.
	StartOffsets []int `pulumi:"startOffsets"`
	// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
	StartTimestamp *int `pulumi:"startTimestamp"`
	// The Kafka topic you want to subscribe to.
	Topic *string `pulumi:"topic"`
	// Set the value format explicitly.
	ValueFormat *SourceKafkaValueFormat `pulumi:"valueFormat"`
}

type SourceKafkaState struct {
	// The cluster to maintain this source. If not specified, the size option must be specified.
	ClusterName pulumi.StringPtrInput
	// The identifier for the source database.
	DatabaseName pulumi.StringPtrInput
	// How Materialize should interpret records (e.g. append-only, upsert)..
	Envelope SourceKafkaEnvelopePtrInput
	// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
	Format SourceKafkaFormatPtrInput
	// Include message headers.
	IncludeHeaders pulumi.BoolPtrInput
	// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
	IncludeKey pulumi.BoolPtrInput
	// Include an offset column containing the Kafka message offset.
	IncludeOffset pulumi.BoolPtrInput
	// Include a partition column containing the Kafka message partition
	IncludePartition pulumi.BoolPtrInput
	// Include a timestamp column containing the Kafka message timestamp.
	IncludeTimestamp pulumi.BoolPtrInput
	// The Kafka connection to use in the source.
	KafkaConnection SourceKafkaKafkaConnectionPtrInput
	// Set the key format explicitly.
	KeyFormat SourceKafkaKeyFormatPtrInput
	// The identifier for the source.
	Name pulumi.StringPtrInput
	// Declare a set of columns as a primary key.
	PrimaryKeys pulumi.StringArrayInput
	// The fully qualified name of the source.
	QualifiedSqlName pulumi.StringPtrInput
	// The identifier for the source schema.
	SchemaName pulumi.StringPtrInput
	// The size of the source.
	Size pulumi.StringPtrInput
	// The type of source.
	SourceType pulumi.StringPtrInput
	// Read partitions from the specified offset.
	StartOffsets pulumi.IntArrayInput
	// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
	StartTimestamp pulumi.IntPtrInput
	// The Kafka topic you want to subscribe to.
	Topic pulumi.StringPtrInput
	// Set the value format explicitly.
	ValueFormat SourceKafkaValueFormatPtrInput
}

func (SourceKafkaState) ElementType() reflect.Type {
	return reflect.TypeOf((*sourceKafkaState)(nil)).Elem()
}

type sourceKafkaArgs struct {
	// The cluster to maintain this source. If not specified, the size option must be specified.
	ClusterName *string `pulumi:"clusterName"`
	// The identifier for the source database.
	DatabaseName *string `pulumi:"databaseName"`
	// How Materialize should interpret records (e.g. append-only, upsert)..
	Envelope *SourceKafkaEnvelope `pulumi:"envelope"`
	// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
	Format *SourceKafkaFormat `pulumi:"format"`
	// Include message headers.
	IncludeHeaders *bool `pulumi:"includeHeaders"`
	// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
	IncludeKey *bool `pulumi:"includeKey"`
	// Include an offset column containing the Kafka message offset.
	IncludeOffset *bool `pulumi:"includeOffset"`
	// Include a partition column containing the Kafka message partition
	IncludePartition *bool `pulumi:"includePartition"`
	// Include a timestamp column containing the Kafka message timestamp.
	IncludeTimestamp *bool `pulumi:"includeTimestamp"`
	// The Kafka connection to use in the source.
	KafkaConnection SourceKafkaKafkaConnection `pulumi:"kafkaConnection"`
	// Set the key format explicitly.
	KeyFormat *SourceKafkaKeyFormat `pulumi:"keyFormat"`
	// The identifier for the source.
	Name *string `pulumi:"name"`
	// Declare a set of columns as a primary key.
	PrimaryKeys []string `pulumi:"primaryKeys"`
	// The identifier for the source schema.
	SchemaName *string `pulumi:"schemaName"`
	// The size of the source.
	Size *string `pulumi:"size"`
	// Read partitions from the specified offset.
	StartOffsets []int `pulumi:"startOffsets"`
	// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
	StartTimestamp *int `pulumi:"startTimestamp"`
	// The Kafka topic you want to subscribe to.
	Topic string `pulumi:"topic"`
	// Set the value format explicitly.
	ValueFormat *SourceKafkaValueFormat `pulumi:"valueFormat"`
}

// The set of arguments for constructing a SourceKafka resource.
type SourceKafkaArgs struct {
	// The cluster to maintain this source. If not specified, the size option must be specified.
	ClusterName pulumi.StringPtrInput
	// The identifier for the source database.
	DatabaseName pulumi.StringPtrInput
	// How Materialize should interpret records (e.g. append-only, upsert)..
	Envelope SourceKafkaEnvelopePtrInput
	// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
	Format SourceKafkaFormatPtrInput
	// Include message headers.
	IncludeHeaders pulumi.BoolPtrInput
	// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
	IncludeKey pulumi.BoolPtrInput
	// Include an offset column containing the Kafka message offset.
	IncludeOffset pulumi.BoolPtrInput
	// Include a partition column containing the Kafka message partition
	IncludePartition pulumi.BoolPtrInput
	// Include a timestamp column containing the Kafka message timestamp.
	IncludeTimestamp pulumi.BoolPtrInput
	// The Kafka connection to use in the source.
	KafkaConnection SourceKafkaKafkaConnectionInput
	// Set the key format explicitly.
	KeyFormat SourceKafkaKeyFormatPtrInput
	// The identifier for the source.
	Name pulumi.StringPtrInput
	// Declare a set of columns as a primary key.
	PrimaryKeys pulumi.StringArrayInput
	// The identifier for the source schema.
	SchemaName pulumi.StringPtrInput
	// The size of the source.
	Size pulumi.StringPtrInput
	// Read partitions from the specified offset.
	StartOffsets pulumi.IntArrayInput
	// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
	StartTimestamp pulumi.IntPtrInput
	// The Kafka topic you want to subscribe to.
	Topic pulumi.StringInput
	// Set the value format explicitly.
	ValueFormat SourceKafkaValueFormatPtrInput
}

func (SourceKafkaArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*sourceKafkaArgs)(nil)).Elem()
}

type SourceKafkaInput interface {
	pulumi.Input

	ToSourceKafkaOutput() SourceKafkaOutput
	ToSourceKafkaOutputWithContext(ctx context.Context) SourceKafkaOutput
}

func (*SourceKafka) ElementType() reflect.Type {
	return reflect.TypeOf((**SourceKafka)(nil)).Elem()
}

func (i *SourceKafka) ToSourceKafkaOutput() SourceKafkaOutput {
	return i.ToSourceKafkaOutputWithContext(context.Background())
}

func (i *SourceKafka) ToSourceKafkaOutputWithContext(ctx context.Context) SourceKafkaOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SourceKafkaOutput)
}

// SourceKafkaArrayInput is an input type that accepts SourceKafkaArray and SourceKafkaArrayOutput values.
// You can construct a concrete instance of `SourceKafkaArrayInput` via:
//
//	SourceKafkaArray{ SourceKafkaArgs{...} }
type SourceKafkaArrayInput interface {
	pulumi.Input

	ToSourceKafkaArrayOutput() SourceKafkaArrayOutput
	ToSourceKafkaArrayOutputWithContext(context.Context) SourceKafkaArrayOutput
}

type SourceKafkaArray []SourceKafkaInput

func (SourceKafkaArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*SourceKafka)(nil)).Elem()
}

func (i SourceKafkaArray) ToSourceKafkaArrayOutput() SourceKafkaArrayOutput {
	return i.ToSourceKafkaArrayOutputWithContext(context.Background())
}

func (i SourceKafkaArray) ToSourceKafkaArrayOutputWithContext(ctx context.Context) SourceKafkaArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SourceKafkaArrayOutput)
}

// SourceKafkaMapInput is an input type that accepts SourceKafkaMap and SourceKafkaMapOutput values.
// You can construct a concrete instance of `SourceKafkaMapInput` via:
//
//	SourceKafkaMap{ "key": SourceKafkaArgs{...} }
type SourceKafkaMapInput interface {
	pulumi.Input

	ToSourceKafkaMapOutput() SourceKafkaMapOutput
	ToSourceKafkaMapOutputWithContext(context.Context) SourceKafkaMapOutput
}

type SourceKafkaMap map[string]SourceKafkaInput

func (SourceKafkaMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*SourceKafka)(nil)).Elem()
}

func (i SourceKafkaMap) ToSourceKafkaMapOutput() SourceKafkaMapOutput {
	return i.ToSourceKafkaMapOutputWithContext(context.Background())
}

func (i SourceKafkaMap) ToSourceKafkaMapOutputWithContext(ctx context.Context) SourceKafkaMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SourceKafkaMapOutput)
}

type SourceKafkaOutput struct{ *pulumi.OutputState }

func (SourceKafkaOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SourceKafka)(nil)).Elem()
}

func (o SourceKafkaOutput) ToSourceKafkaOutput() SourceKafkaOutput {
	return o
}

func (o SourceKafkaOutput) ToSourceKafkaOutputWithContext(ctx context.Context) SourceKafkaOutput {
	return o
}

// The cluster to maintain this source. If not specified, the size option must be specified.
func (o SourceKafkaOutput) ClusterName() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.ClusterName }).(pulumi.StringOutput)
}

// The identifier for the source database.
func (o SourceKafkaOutput) DatabaseName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringPtrOutput { return v.DatabaseName }).(pulumi.StringPtrOutput)
}

// How Materialize should interpret records (e.g. append-only, upsert)..
func (o SourceKafkaOutput) Envelope() SourceKafkaEnvelopePtrOutput {
	return o.ApplyT(func(v *SourceKafka) SourceKafkaEnvelopePtrOutput { return v.Envelope }).(SourceKafkaEnvelopePtrOutput)
}

// How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
func (o SourceKafkaOutput) Format() SourceKafkaFormatPtrOutput {
	return o.ApplyT(func(v *SourceKafka) SourceKafkaFormatPtrOutput { return v.Format }).(SourceKafkaFormatPtrOutput)
}

// Include message headers.
func (o SourceKafkaOutput) IncludeHeaders() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.BoolPtrOutput { return v.IncludeHeaders }).(pulumi.BoolPtrOutput)
}

// Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
func (o SourceKafkaOutput) IncludeKey() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.BoolPtrOutput { return v.IncludeKey }).(pulumi.BoolPtrOutput)
}

// Include an offset column containing the Kafka message offset.
func (o SourceKafkaOutput) IncludeOffset() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.BoolPtrOutput { return v.IncludeOffset }).(pulumi.BoolPtrOutput)
}

// Include a partition column containing the Kafka message partition
func (o SourceKafkaOutput) IncludePartition() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.BoolPtrOutput { return v.IncludePartition }).(pulumi.BoolPtrOutput)
}

// Include a timestamp column containing the Kafka message timestamp.
func (o SourceKafkaOutput) IncludeTimestamp() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.BoolPtrOutput { return v.IncludeTimestamp }).(pulumi.BoolPtrOutput)
}

// The Kafka connection to use in the source.
func (o SourceKafkaOutput) KafkaConnection() SourceKafkaKafkaConnectionOutput {
	return o.ApplyT(func(v *SourceKafka) SourceKafkaKafkaConnectionOutput { return v.KafkaConnection }).(SourceKafkaKafkaConnectionOutput)
}

// Set the key format explicitly.
func (o SourceKafkaOutput) KeyFormat() SourceKafkaKeyFormatPtrOutput {
	return o.ApplyT(func(v *SourceKafka) SourceKafkaKeyFormatPtrOutput { return v.KeyFormat }).(SourceKafkaKeyFormatPtrOutput)
}

// The identifier for the source.
func (o SourceKafkaOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// Declare a set of columns as a primary key.
func (o SourceKafkaOutput) PrimaryKeys() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringArrayOutput { return v.PrimaryKeys }).(pulumi.StringArrayOutput)
}

// The fully qualified name of the source.
func (o SourceKafkaOutput) QualifiedSqlName() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.QualifiedSqlName }).(pulumi.StringOutput)
}

// The identifier for the source schema.
func (o SourceKafkaOutput) SchemaName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringPtrOutput { return v.SchemaName }).(pulumi.StringPtrOutput)
}

// The size of the source.
func (o SourceKafkaOutput) Size() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.Size }).(pulumi.StringOutput)
}

// The type of source.
func (o SourceKafkaOutput) SourceType() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.SourceType }).(pulumi.StringOutput)
}

// Read partitions from the specified offset.
func (o SourceKafkaOutput) StartOffsets() pulumi.IntArrayOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.IntArrayOutput { return v.StartOffsets }).(pulumi.IntArrayOutput)
}

// Use the specified value to set "START OFFSET" based on the Kafka timestamp.
func (o SourceKafkaOutput) StartTimestamp() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.IntPtrOutput { return v.StartTimestamp }).(pulumi.IntPtrOutput)
}

// The Kafka topic you want to subscribe to.
func (o SourceKafkaOutput) Topic() pulumi.StringOutput {
	return o.ApplyT(func(v *SourceKafka) pulumi.StringOutput { return v.Topic }).(pulumi.StringOutput)
}

// Set the value format explicitly.
func (o SourceKafkaOutput) ValueFormat() SourceKafkaValueFormatPtrOutput {
	return o.ApplyT(func(v *SourceKafka) SourceKafkaValueFormatPtrOutput { return v.ValueFormat }).(SourceKafkaValueFormatPtrOutput)
}

type SourceKafkaArrayOutput struct{ *pulumi.OutputState }

func (SourceKafkaArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*SourceKafka)(nil)).Elem()
}

func (o SourceKafkaArrayOutput) ToSourceKafkaArrayOutput() SourceKafkaArrayOutput {
	return o
}

func (o SourceKafkaArrayOutput) ToSourceKafkaArrayOutputWithContext(ctx context.Context) SourceKafkaArrayOutput {
	return o
}

func (o SourceKafkaArrayOutput) Index(i pulumi.IntInput) SourceKafkaOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *SourceKafka {
		return vs[0].([]*SourceKafka)[vs[1].(int)]
	}).(SourceKafkaOutput)
}

type SourceKafkaMapOutput struct{ *pulumi.OutputState }

func (SourceKafkaMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*SourceKafka)(nil)).Elem()
}

func (o SourceKafkaMapOutput) ToSourceKafkaMapOutput() SourceKafkaMapOutput {
	return o
}

func (o SourceKafkaMapOutput) ToSourceKafkaMapOutputWithContext(ctx context.Context) SourceKafkaMapOutput {
	return o
}

func (o SourceKafkaMapOutput) MapIndex(k pulumi.StringInput) SourceKafkaOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *SourceKafka {
		return vs[0].(map[string]*SourceKafka)[vs[1].(string)]
	}).(SourceKafkaOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*SourceKafkaInput)(nil)).Elem(), &SourceKafka{})
	pulumi.RegisterInputType(reflect.TypeOf((*SourceKafkaArrayInput)(nil)).Elem(), SourceKafkaArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*SourceKafkaMapInput)(nil)).Elem(), SourceKafkaMap{})
	pulumi.RegisterOutputType(SourceKafkaOutput{})
	pulumi.RegisterOutputType(SourceKafkaArrayOutput{})
	pulumi.RegisterOutputType(SourceKafkaMapOutput{})
}
