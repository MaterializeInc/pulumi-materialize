// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs } from "./types";
import * as utilities from "./utilities";

/**
 * A source describes an external system you want Materialize to read data from, and provides details about how to decode and interpret that data.
 *
 * ## Example Usage
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as materialize from "@pulumi/materialize";
 *
 * const exampleSourceKafka = new materialize.SourceKafka("example_source_kafka", {
 *     envelope: {
 *         none: true,
 *     },
 *     format: {
 *         avro: {
 *             schemaRegistryConnection: {
 *                 databaseName: "database",
 *                 name: "csr_connection",
 *                 schemaName: "schema",
 *             },
 *         },
 *     },
 *     kafkaConnection: {
 *         databaseName: "database",
 *         name: "kafka_connection",
 *         schemaName: "schema",
 *     },
 *     schemaName: "schema",
 *     size: "3xsmall",
 * });
 * ```
 *
 * ## Import
 *
 * # Sources can be imported using the source id
 *
 * ```sh
 *  $ pulumi import materialize:index/sourceKafka:SourceKafka example_source_kafka <source_id>
 * ```
 */
export class SourceKafka extends pulumi.CustomResource {
    /**
     * Get an existing SourceKafka resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: SourceKafkaState, opts?: pulumi.CustomResourceOptions): SourceKafka {
        return new SourceKafka(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'materialize:index/sourceKafka:SourceKafka';

    /**
     * Returns true if the given object is an instance of SourceKafka.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is SourceKafka {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === SourceKafka.__pulumiType;
    }

    /**
     * The cluster to maintain this source. If not specified, the size option must be specified.
     */
    public readonly clusterName!: pulumi.Output<string>;
    /**
     * The identifier for the source database.
     */
    public readonly databaseName!: pulumi.Output<string | undefined>;
    /**
     * How Materialize should interpret records (e.g. append-only, upsert)..
     */
    public readonly envelope!: pulumi.Output<outputs.SourceKafkaEnvelope | undefined>;
    /**
     * How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
     */
    public readonly format!: pulumi.Output<outputs.SourceKafkaFormat | undefined>;
    /**
     * Include message headers.
     */
    public readonly includeHeaders!: pulumi.Output<boolean | undefined>;
    /**
     * Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
     */
    public readonly includeKey!: pulumi.Output<boolean | undefined>;
    /**
     * Include an offset column containing the Kafka message offset.
     */
    public readonly includeOffset!: pulumi.Output<boolean | undefined>;
    /**
     * Include a partition column containing the Kafka message partition
     */
    public readonly includePartition!: pulumi.Output<boolean | undefined>;
    /**
     * Include a timestamp column containing the Kafka message timestamp.
     */
    public readonly includeTimestamp!: pulumi.Output<boolean | undefined>;
    /**
     * The Kafka connection to use in the source.
     */
    public readonly kafkaConnection!: pulumi.Output<outputs.SourceKafkaKafkaConnection>;
    /**
     * Set the key format explicitly.
     */
    public readonly keyFormat!: pulumi.Output<outputs.SourceKafkaKeyFormat | undefined>;
    /**
     * The identifier for the source.
     */
    public readonly name!: pulumi.Output<string>;
    /**
     * Declare a set of columns as a primary key.
     */
    public readonly primaryKeys!: pulumi.Output<string[] | undefined>;
    /**
     * The fully qualified name of the source.
     */
    public /*out*/ readonly qualifiedSqlName!: pulumi.Output<string>;
    /**
     * The identifier for the source schema.
     */
    public readonly schemaName!: pulumi.Output<string | undefined>;
    /**
     * The size of the source.
     */
    public readonly size!: pulumi.Output<string>;
    /**
     * The type of source.
     */
    public /*out*/ readonly sourceType!: pulumi.Output<string>;
    /**
     * Read partitions from the specified offset.
     */
    public readonly startOffsets!: pulumi.Output<number[] | undefined>;
    /**
     * Use the specified value to set "START OFFSET" based on the Kafka timestamp.
     */
    public readonly startTimestamp!: pulumi.Output<number | undefined>;
    /**
     * The Kafka topic you want to subscribe to.
     */
    public readonly topic!: pulumi.Output<string>;
    /**
     * Set the value format explicitly.
     */
    public readonly valueFormat!: pulumi.Output<outputs.SourceKafkaValueFormat | undefined>;

    /**
     * Create a SourceKafka resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: SourceKafkaArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: SourceKafkaArgs | SourceKafkaState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as SourceKafkaState | undefined;
            resourceInputs["clusterName"] = state ? state.clusterName : undefined;
            resourceInputs["databaseName"] = state ? state.databaseName : undefined;
            resourceInputs["envelope"] = state ? state.envelope : undefined;
            resourceInputs["format"] = state ? state.format : undefined;
            resourceInputs["includeHeaders"] = state ? state.includeHeaders : undefined;
            resourceInputs["includeKey"] = state ? state.includeKey : undefined;
            resourceInputs["includeOffset"] = state ? state.includeOffset : undefined;
            resourceInputs["includePartition"] = state ? state.includePartition : undefined;
            resourceInputs["includeTimestamp"] = state ? state.includeTimestamp : undefined;
            resourceInputs["kafkaConnection"] = state ? state.kafkaConnection : undefined;
            resourceInputs["keyFormat"] = state ? state.keyFormat : undefined;
            resourceInputs["name"] = state ? state.name : undefined;
            resourceInputs["primaryKeys"] = state ? state.primaryKeys : undefined;
            resourceInputs["qualifiedSqlName"] = state ? state.qualifiedSqlName : undefined;
            resourceInputs["schemaName"] = state ? state.schemaName : undefined;
            resourceInputs["size"] = state ? state.size : undefined;
            resourceInputs["sourceType"] = state ? state.sourceType : undefined;
            resourceInputs["startOffsets"] = state ? state.startOffsets : undefined;
            resourceInputs["startTimestamp"] = state ? state.startTimestamp : undefined;
            resourceInputs["topic"] = state ? state.topic : undefined;
            resourceInputs["valueFormat"] = state ? state.valueFormat : undefined;
        } else {
            const args = argsOrState as SourceKafkaArgs | undefined;
            if ((!args || args.kafkaConnection === undefined) && !opts.urn) {
                throw new Error("Missing required property 'kafkaConnection'");
            }
            if ((!args || args.topic === undefined) && !opts.urn) {
                throw new Error("Missing required property 'topic'");
            }
            resourceInputs["clusterName"] = args ? args.clusterName : undefined;
            resourceInputs["databaseName"] = args ? args.databaseName : undefined;
            resourceInputs["envelope"] = args ? args.envelope : undefined;
            resourceInputs["format"] = args ? args.format : undefined;
            resourceInputs["includeHeaders"] = args ? args.includeHeaders : undefined;
            resourceInputs["includeKey"] = args ? args.includeKey : undefined;
            resourceInputs["includeOffset"] = args ? args.includeOffset : undefined;
            resourceInputs["includePartition"] = args ? args.includePartition : undefined;
            resourceInputs["includeTimestamp"] = args ? args.includeTimestamp : undefined;
            resourceInputs["kafkaConnection"] = args ? args.kafkaConnection : undefined;
            resourceInputs["keyFormat"] = args ? args.keyFormat : undefined;
            resourceInputs["name"] = args ? args.name : undefined;
            resourceInputs["primaryKeys"] = args ? args.primaryKeys : undefined;
            resourceInputs["schemaName"] = args ? args.schemaName : undefined;
            resourceInputs["size"] = args ? args.size : undefined;
            resourceInputs["startOffsets"] = args ? args.startOffsets : undefined;
            resourceInputs["startTimestamp"] = args ? args.startTimestamp : undefined;
            resourceInputs["topic"] = args ? args.topic : undefined;
            resourceInputs["valueFormat"] = args ? args.valueFormat : undefined;
            resourceInputs["qualifiedSqlName"] = undefined /*out*/;
            resourceInputs["sourceType"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(SourceKafka.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering SourceKafka resources.
 */
export interface SourceKafkaState {
    /**
     * The cluster to maintain this source. If not specified, the size option must be specified.
     */
    clusterName?: pulumi.Input<string>;
    /**
     * The identifier for the source database.
     */
    databaseName?: pulumi.Input<string>;
    /**
     * How Materialize should interpret records (e.g. append-only, upsert)..
     */
    envelope?: pulumi.Input<inputs.SourceKafkaEnvelope>;
    /**
     * How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
     */
    format?: pulumi.Input<inputs.SourceKafkaFormat>;
    /**
     * Include message headers.
     */
    includeHeaders?: pulumi.Input<boolean>;
    /**
     * Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
     */
    includeKey?: pulumi.Input<boolean>;
    /**
     * Include an offset column containing the Kafka message offset.
     */
    includeOffset?: pulumi.Input<boolean>;
    /**
     * Include a partition column containing the Kafka message partition
     */
    includePartition?: pulumi.Input<boolean>;
    /**
     * Include a timestamp column containing the Kafka message timestamp.
     */
    includeTimestamp?: pulumi.Input<boolean>;
    /**
     * The Kafka connection to use in the source.
     */
    kafkaConnection?: pulumi.Input<inputs.SourceKafkaKafkaConnection>;
    /**
     * Set the key format explicitly.
     */
    keyFormat?: pulumi.Input<inputs.SourceKafkaKeyFormat>;
    /**
     * The identifier for the source.
     */
    name?: pulumi.Input<string>;
    /**
     * Declare a set of columns as a primary key.
     */
    primaryKeys?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * The fully qualified name of the source.
     */
    qualifiedSqlName?: pulumi.Input<string>;
    /**
     * The identifier for the source schema.
     */
    schemaName?: pulumi.Input<string>;
    /**
     * The size of the source.
     */
    size?: pulumi.Input<string>;
    /**
     * The type of source.
     */
    sourceType?: pulumi.Input<string>;
    /**
     * Read partitions from the specified offset.
     */
    startOffsets?: pulumi.Input<pulumi.Input<number>[]>;
    /**
     * Use the specified value to set "START OFFSET" based on the Kafka timestamp.
     */
    startTimestamp?: pulumi.Input<number>;
    /**
     * The Kafka topic you want to subscribe to.
     */
    topic?: pulumi.Input<string>;
    /**
     * Set the value format explicitly.
     */
    valueFormat?: pulumi.Input<inputs.SourceKafkaValueFormat>;
}

/**
 * The set of arguments for constructing a SourceKafka resource.
 */
export interface SourceKafkaArgs {
    /**
     * The cluster to maintain this source. If not specified, the size option must be specified.
     */
    clusterName?: pulumi.Input<string>;
    /**
     * The identifier for the source database.
     */
    databaseName?: pulumi.Input<string>;
    /**
     * How Materialize should interpret records (e.g. append-only, upsert)..
     */
    envelope?: pulumi.Input<inputs.SourceKafkaEnvelope>;
    /**
     * How to decode raw bytes from different formats into data structures Materialize can understand at runtime.
     */
    format?: pulumi.Input<inputs.SourceKafkaFormat>;
    /**
     * Include message headers.
     */
    includeHeaders?: pulumi.Input<boolean>;
    /**
     * Include a column containing the Kafka message key. If the key is encoded using a format that includes schemas, the column will take its name from the schema. For unnamed formats (e.g. TEXT), the column will be named "key".
     */
    includeKey?: pulumi.Input<boolean>;
    /**
     * Include an offset column containing the Kafka message offset.
     */
    includeOffset?: pulumi.Input<boolean>;
    /**
     * Include a partition column containing the Kafka message partition
     */
    includePartition?: pulumi.Input<boolean>;
    /**
     * Include a timestamp column containing the Kafka message timestamp.
     */
    includeTimestamp?: pulumi.Input<boolean>;
    /**
     * The Kafka connection to use in the source.
     */
    kafkaConnection: pulumi.Input<inputs.SourceKafkaKafkaConnection>;
    /**
     * Set the key format explicitly.
     */
    keyFormat?: pulumi.Input<inputs.SourceKafkaKeyFormat>;
    /**
     * The identifier for the source.
     */
    name?: pulumi.Input<string>;
    /**
     * Declare a set of columns as a primary key.
     */
    primaryKeys?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * The identifier for the source schema.
     */
    schemaName?: pulumi.Input<string>;
    /**
     * The size of the source.
     */
    size?: pulumi.Input<string>;
    /**
     * Read partitions from the specified offset.
     */
    startOffsets?: pulumi.Input<pulumi.Input<number>[]>;
    /**
     * Use the specified value to set "START OFFSET" based on the Kafka timestamp.
     */
    startTimestamp?: pulumi.Input<number>;
    /**
     * The Kafka topic you want to subscribe to.
     */
    topic: pulumi.Input<string>;
    /**
     * Set the value format explicitly.
     */
    valueFormat?: pulumi.Input<inputs.SourceKafkaValueFormat>;
}
